{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pycocotools.mask as mask_util\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import py360convert from lib folder\n",
    "import sys\n",
    "sys.path.insert(0, '/home/lombardo/sidewalk-accessibility-features/lib/py360convert')\n",
    "\n",
    "import py360convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_faces(index):\n",
    "    # Function that maps the face index to the corresponding face\n",
    "    # Mapping: 0F 1R 2B 3L 4U 5D\n",
    "    # For example: index == 0, return 'front'\n",
    "    if index == 0:\n",
    "        return 'front'\n",
    "    elif index == 1:\n",
    "        return 'right'\n",
    "    elif index == 2:\n",
    "        return 'back'\n",
    "    elif index == 3:\n",
    "        return 'left'\n",
    "    elif index == 4:\n",
    "        return 'top'\n",
    "    elif index == 5:\n",
    "        return 'bottom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_map_faces(face):\n",
    "    # Function that maps the face name to the corresponding index\n",
    "    # Mapping: 'front' -> 0, 'right' -> 1, 'back' -> 2, 'left' -> 3, 'top' -> 4, 'bottom' -> 5\n",
    "    face_mapping = {'front': 0, 'right': 1, 'back': 2, 'left': 3, 'top': 4, 'bottom': 5}\n",
    "    return face_mapping.get(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pano_id_example = '9VW3AUbKBdSPqnURnwRSLQ'\n",
    "reoriented_path = os.path.join('/var/scratch/lombardo/download_PS/reoriented', f'{pano_id_example}.jpg')\n",
    "\n",
    "# Open image\n",
    "img = cv2.imread(reoriented_path)\n",
    "# Convert to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Open labels_reprojected.csv\n",
    "labels_reprojected_path = '/var/scratch/lombardo/download_PS/labels_1024_reprojected.csv'\n",
    "\n",
    "# Test with a single pano_id\n",
    "labels_reprojected = pd.read_csv(labels_reprojected_path)\n",
    "\n",
    "# labels_reprojected contains (reoriented_pano_x,reoriented_pano_y) coordinates. For each label with 'gsv_panorama_id' == pano_id_example,\n",
    "# we want to retrieve the corresponding (reoriented_pano_x,reoriented_pano_y) coordinates and visualize them on the reoriented image.\n",
    "gt_points = []\n",
    "for index, row in labels_reprojected.iterrows():\n",
    "    if row['gsv_panorama_id'] == pano_id_example:\n",
    "        # Retrieve coordinates\n",
    "        image_width = row['pano_width']\n",
    "        image_height = row['pano_height']\n",
    "        sv_image_x = row['pano_x']\n",
    "        sv_image_y = row['pano_y']\n",
    "        print(f'')\n",
    "        print(f'Coordinates before scaling: {sv_image_y},{sv_image_x}')\n",
    "        scaled_x = row['scaled_pano_x']\n",
    "        scaled_y = row['scaled_pano_y']\n",
    "        reoriented_pano_x = row['reoriented_pano_x']\n",
    "        reoriented_pano_y = row['reoriented_pano_y']\n",
    "        print(f'Coordinates before reorientation: {scaled_y},{scaled_x}')\n",
    "        print(f'Coordinates after reorientation: {reoriented_pano_y},{reoriented_pano_x}')\n",
    "        \n",
    "        # Retrieve coordinates\n",
    "        #reoriented_pano_x = row['reoriented_pano_x']\n",
    "        #reoriented_pano_y = row['reoriented_pano_y']\n",
    "        reprojected_pano_x = row['reprojected_pano_x']\n",
    "        reprojected_pano_y = row['reprojected_pano_y']\n",
    "        face_idx = row['face_idx']\n",
    "        print(f'Face idx: {face_idx}')\n",
    "        print(f'Coordinates after reprojection: {reprojected_pano_y},{reprojected_pano_x}')\n",
    "\n",
    "        gt_points.append([face_idx, (reprojected_pano_y, reprojected_pano_x)])\n",
    "\n",
    "print(gt_points)\n",
    "\n",
    "# Initialize a dictionary to store the subplots for each face\n",
    "subplots = {}\n",
    "\n",
    "# Visualize the points\n",
    "for point in gt_points:\n",
    "    face = map_faces(point[0])\n",
    "    print(f'Face: {face}')\n",
    "    \n",
    "    if face not in subplots:\n",
    "        # Create a new subplot for the face\n",
    "        subplots[face] = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    mask_path = f'/var/scratch/lombardo/download_PS/masks/{pano_id_example}/{face}.png'\n",
    "    path = f'/var/scratch/lombardo/download_PS/reprojected/{pano_id_example}/{face}.png'\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Resize mask to match image size\n",
    "    mask = cv2.resize(mask, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # Threshold the image\n",
    "    _, thresh = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Apply connected components with statistics\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n",
    "\n",
    "    print('Number of connected components: ' + str(num_labels - 1))\n",
    "\n",
    "    # Create an empty image to visualize the connected components\n",
    "    output = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Assign a unique color for each connected component\n",
    "    for i in range(1, num_labels):\n",
    "        color = (np.random.randint(0, 256), np.random.randint(0, 256), np.random.randint(0, 256))\n",
    "        output[labels == i] = color\n",
    "\n",
    "        # Get the area of the connected component from the stats array\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "\n",
    "        #print(f\"Component {i}: Area = {area}, Color = {color}\")\n",
    "\n",
    "    # Get the subplot and plot img, output, and the point\n",
    "    plt.figure(subplots[face].number)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(output, alpha=0.4)\n",
    "    plt.scatter(point[1][1], point[1][0], color='red', s=7)\n",
    "\n",
    "# Show all the subplots\n",
    "for face, subplot in subplots.items():\n",
    "    plt.figure(subplot.number)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "'''/var/scratch/lombardo/download_PS/reoriented/6mRBTtpLi7Bi3Tgu_fxOtA.jpg\n",
    "Coordinates before reorientation: 699,1743\n",
    "Coordinates after reorientation: 699,140\n",
    "Coordinates after reprojection: 877,276\n",
    "[[2, (877, 276)]]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_example_path = os.path.join('/var/scratch/lombardo/download_PS/reoriented', f'{pano_id_example}.jpg')\n",
    "print(img_example_path)\n",
    "\n",
    "# Open image\n",
    "img = cv2.imread(img_example_path)\n",
    "# Convert to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "print(img.shape)\n",
    "# Show image\n",
    "# Figure: medium size\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "plt.scatter(1459,590,color='red', s=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image from 'res/equirectangular.png'\n",
    "img_path = 'res/equirectangular.png'\n",
    "example_pano = 'res/example_pano.png'\n",
    "img = cv2.imread(example_pano)\n",
    "# Convert to RGB\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Draw a red point at coordinates (400,800)\n",
    "cv2.circle(img, (500,680), 10, (0,0,255), -1)\n",
    "\n",
    "# Save image as example_pano_triangle.png\n",
    "cv2.imwrite('res/example_pano_point.png', img)\n",
    "\n",
    "# Convert to cubemap\n",
    "cubemap = py360convert.e2c(img, face_w=1024)\n",
    "# Print dtype of cubemap\n",
    "print(cubemap.dtype)\n",
    "# Flip horizontally the images of cubemap at indices 0 and 2\n",
    "#cubemap[[0,2]] = cubemap[[0,2]][:,::-1]\n",
    "# Save cubemap as example_pano_triangle_cb.png\n",
    "cv2.imwrite('res/example_pano_point_cb.png', cubemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Assuming you have 5 images and their corresponding label qualities\n",
    "img1 = plt.imread('res/problems_clustering/label_quality/visualize__-7gKmiV-npQwLy_CD3v7Q_back.png')\n",
    "img2 = plt.imread('res/problems_clustering/label_quality/visualize__A3VGaMhL4XcGQxtFUiAfA_back.png')\n",
    "img3 = plt.imread('res/problems_clustering/label_quality/visualize__Nkwp741bbV44txP6PRo1A_right.png')\n",
    "img4 = plt.imread('res/problems_clustering/label_quality/visualize_-RHS-ZYDt0sCDy2aS4AwOQ_right.png')\n",
    "img5 = plt.imread('res/problems_clustering/label_quality/visualize_0sAG8-ozIw7wANw_hsTCHA_back.png')\n",
    "img6 = plt.imread('res/problems_clustering/label_not_found/visualize__WZ_Q2QCOe9NEypucJnClQ_left.png')\n",
    "img7 = plt.imread('res/problems_clustering/label_not_found/visualize_-juZj6rt9x1unIRBa0D7fQ_right.png')\n",
    "img8 = plt.imread('res/problems_clustering/label_not_found/visualize_-qi4eywPKVd0sHlHqcWVkA_left.png')\n",
    "img9 = plt.imread('res/problems_clustering/label_not_found/visualize_0E_M8eWvyACpG_fUq4TFrQ_left.png')\n",
    "img10 = plt.imread('res/problems_clustering/label_not_found/visualize_0sKrgbDBfDrizWjCnXI0FQ_right.png')\n",
    "img11 = plt.imread('res/problems_clustering/all_labels_not_found/visualize__pjTmksYX5Vpgoqm_GSOKA_right.png')\n",
    "img12 = plt.imread('res/problems_clustering/all_labels_not_found/visualize__ZuTw7GC38rShAUjL-dLmQ_left.png')\n",
    "img13 = plt.imread('res/problems_clustering/all_labels_not_found/visualize_-ELBA4Cjr_WBoetht0GVbQ_right.png')\n",
    "img14 = plt.imread('res/problems_clustering/all_labels_not_found/visualize_-RHS-ZYDt0sCDy2aS4AwOQ_left.png')\n",
    "img15 = plt.imread('res/problems_clustering/all_labels_not_found/visualize_0wLMkTJ7IaDz8mJm3uNeHg_front.png')\n",
    "img16 = plt.imread('res/problems_clustering/not_relevant_objects/visualize_-CD3qZk9zyeumBU_w7Yl5A_front.png')\n",
    "img17 = plt.imread('res/problems_clustering/not_relevant_objects/visualize_-rU6BN-wNeRclahZxn2nug_back.png')\n",
    "img18 = plt.imread('res/problems_clustering/not_relevant_objects/visualize_0h2CfQQ_Ca5sRgU5Zze01g_right.png')\n",
    "img19 = plt.imread('res/problems_clustering/not_relevant_objects/visualize_0NjLmtmwNh95YlOyyydtnA_front.png')\n",
    "img20 = plt.imread('res/problems_clustering/not_relevant_objects/visualize_0vrKe1xEAZkxUXYhtwRtaQ_front.png')\n",
    "img21 = plt.imread('res/problems_clustering/multiple-objects_mask/visualize__ZuTw7GC38rShAUjL-dLmQ_front.png')\n",
    "img22 = plt.imread('res/problems_clustering/multiple-objects_mask/visualize_-ay7zopCWOrSjeUuirk91A_right.png')\n",
    "img23 = plt.imread('res/problems_clustering/multiple-objects_mask/visualize_-WI1nKjShmeFVRGsrFsFpw_front.png')\n",
    "img24 = plt.imread('res/problems_clustering/multiple-objects_mask/visualize_0FHr9qesIVgabJ8hR7Uf2A_back.png')\n",
    "img25 = plt.imread('res/problems_clustering/multiple-objects_mask/visualize_1GIXHFehrd1Xbu2JbmzlFw_left.png')\n",
    "img26 = plt.imread('res/problems_clustering/noisy_masks/visualize_2fPjt5siCmoOpY1kMe3t3w_left.png')\n",
    "img27 = plt.imread('res/problems_clustering/noisy_masks/visualize_2iKOp2S2_K4WrxfLS1jDlA_right.png')\n",
    "img28 = plt.imread('res/problems_clustering/noisy_masks/visualize_2qShzHuplxE5Zp02V3Fnrw_front.png')\n",
    "img29 = plt.imread('res/problems_clustering/noisy_masks/visualize_2Yg6fuCTqr_5Uc5IcGPs4w_front.png')\n",
    "img30 = plt.imread('res/problems_clustering/noisy_masks/visualize_3iQ5g0gAW8uyiTwiRNytaQ_back.png')\n",
    "images = [img1, img2, img3, img4, img5, img6, img7, \\\n",
    "            img8, img9, img10, img11, img12, img13, \\\n",
    "            img14, img15, img16, img17, img18, img19, \\\n",
    "            img20, img21, img22, img23, img24, img25, \\\n",
    "            img26, img27, img28, img29, img30]\n",
    "label_qualities = [4, 3, 5, 2, 4] * 6  # Placeholder label qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create images made of two rows and five random images\n",
    "# images = np.random.randint(0, 255, size=(10, 256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "# Define the y-axis labels for each row\n",
    "y_labels = ['Label quality', 'Label not found', 'All labels not found', 'Not relevant objects', \\\n",
    "            'Multiple-objects masks', 'Noisy masks']\n",
    "\n",
    "# Define grid\n",
    "gs = gridspec.GridSpec(6, 6, width_ratios=[1, 5, 5, 5, 5, 5]) \n",
    "\n",
    "fig = plt.figure(figsize=(12, 14))\n",
    "\n",
    "# Iterate over each row and subplot, plot the image, and set the y-axis label\n",
    "for i in range(6):\n",
    "    ax = plt.subplot(gs[i, 0])\n",
    "    ax.text(0.5, 0.5, y_labels[i], ha='center', va='center', rotation='vertical', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "    for j in range(5):\n",
    "        ax = plt.subplot(gs[i, j+1])\n",
    "        ax.imshow(images[i * 5 + j])  # Plot the image\n",
    "        ax.axis('off')  # Turn off the axis for cleaner display\n",
    "\n",
    "# Adjust the spacing between subplots and display the plot\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "#fig.savefig('res/problems_clustering/plot.png', bbox_inches='tight')\n",
    "\n",
    "'''# Create subplots for each image\n",
    "fig, axs = plt.subplots(6, 5, figsize=(12, 14))\n",
    "\n",
    "# Define the y-axis labels for each row\n",
    "y_labels = ['Label quality', 'Label not found', 'All labels not found', 'Not relevant objects', \\\n",
    "            'Multiple-objects masks', 'Noisy masks']\n",
    "\n",
    "# Iterate over each row and subplot, plot the image, and set the y-axis label\n",
    "for i, row in enumerate(axs):\n",
    "    for j, ax in enumerate(row):\n",
    "        ax.imshow(images[i * 5 + j])  # Plot the image\n",
    "        ax.set_axis_off()  # Turn off the axis for cleaner display\n",
    "        \n",
    "        # Add the vertical text label only for the first subplot in each row\n",
    "        if j == 0:\n",
    "            ax.text(-10, -10, y_labels[i], rotation='vertical', va='top', ha='right', fontsize=10)\n",
    "\n",
    "#plt.tight_layout()\n",
    "# Adjust the spacing between subplots and display the plot\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "plt.show()\n",
    "# Save the figure'''\n",
    "\n",
    "fig.savefig('res/problems_clustering/plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Load your data\n",
    "df1 = pd.read_csv('res/problems_clustering_baseline.csv')\n",
    "df2 = pd.read_csv('res/problems_clustering_context.csv')\n",
    "\n",
    "# Define labels\n",
    "#labels = ['Label quality', 'Label not found', 'All labels not found', 'Not relevant objects', 'Multiple-objects masks', 'Noisy masks']\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def count_labels(df, column_name):\n",
    "    # Initialize a counter\n",
    "    counter = Counter()\n",
    "    \n",
    "    # Iterate over the rows of the dataframe\n",
    "    for labels in df[column_name]:\n",
    "        # Skip NA values\n",
    "        if pd.notnull(labels):\n",
    "            # Split the string into labels and strip whitespace\n",
    "            labels = [label.strip().lower() for label in labels.split(',')]\n",
    "            \n",
    "            # Count the labels\n",
    "            counter.update(labels)\n",
    "    \n",
    "    return counter\n",
    "\n",
    "# Count the labels in the 'problem' column\n",
    "counter1 = count_labels(df1, 'problem')\n",
    "counter2 = count_labels(df2, 'problem')\n",
    "\n",
    "# Convert the counters to dataframes\n",
    "df1_counts = pd.DataFrame.from_dict(counter1, orient='index', columns=['Baseline'])\n",
    "df2_counts = pd.DataFrame.from_dict(counter2, orient='index', columns=['Baseline + Context'])\n",
    "\n",
    "# Merge the dataframes\n",
    "df_counts = df1_counts.join(df2_counts, how='outer').fillna(0)\n",
    "\n",
    "# Reset index to make 'index' a column (for seaborn)\n",
    "df_counts.reset_index(level=0, inplace=True)\n",
    "\n",
    "# Rename the 'index' column to 'labels'\n",
    "df_counts.rename(columns={'index': 'labels'}, inplace=True)\n",
    "\n",
    "# Capitalize the first letter of each label\n",
    "df_counts['labels'] = df_counts['labels'].str.capitalize()\n",
    "\n",
    "# Melt the dataframe to make it suitable for seaborn\n",
    "df_counts = df_counts.melt('labels', var_name='Experiments', value_name='counts')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='labels', y='counts', hue='Experiments', data=df_counts)\n",
    "plt.title('Counts of problems in clusters')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Problem categories')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add count numbers as annotations above the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.0f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save in high quality\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('res/problems_clustering/plot2.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "\n",
    "img1_path = 'res/beforeafter/before/visualize_1GYNc35brG1DJCtFYWs8KA_right.png'\n",
    "img2_path = 'res/beforeafter/before/visualize_1VEVLWYfmi0vVyEsXoJD8A_right.png'\n",
    "img3_path = 'res/beforeafter/before/visualize_2atLrFYpUNAyUc7f7M8mzA_back.png'\n",
    "img4_path = 'res/beforeafter/before/visualize_2E3r3TggV5YhVAYv1q0euA_right.png'\n",
    "img5_path = 'res/beforeafter/before/visualize_2ke_0eGW8-nEpc1cFyBM2A_front.png'\n",
    "img6_path = 'res/beforeafter/after/visualize_1GYNc35brG1DJCtFYWs8KA_right.png'\n",
    "img7_path = 'res/beforeafter/after/visualize_1VEVLWYfmi0vVyEsXoJD8A_right.png'\n",
    "img8_path = 'res/beforeafter/after/visualize_2atLrFYpUNAyUc7f7M8mzA_back.png'\n",
    "img9_path = 'res/beforeafter/after/visualize_2E3r3TggV5YhVAYv1q0euA_right.png'\n",
    "img10_path = 'res/beforeafter/after/visualize_2ke_0eGW8-nEpc1cFyBM2A_front.png'\n",
    "\n",
    "# Load images\n",
    "img1 = cv2.imread(img1_path)\n",
    "img2 = cv2.imread(img2_path)\n",
    "img3 = cv2.imread(img3_path)\n",
    "img4 = cv2.imread(img4_path)\n",
    "img5 = cv2.imread(img5_path)\n",
    "img6 = cv2.imread(img6_path)\n",
    "img7 = cv2.imread(img7_path)\n",
    "img8 = cv2.imread(img8_path)\n",
    "img9 = cv2.imread(img9_path)\n",
    "img10 = cv2.imread(img10_path)\n",
    "\n",
    "imgs_baseline = [img1, img2, img3, img4, img5]\n",
    "imgs_context = [img6, img7, img8, img9, img10]\n",
    "\n",
    "# Convert the images in imgs_baseline and imgs_context to RGB\n",
    "imgs_baseline = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in imgs_baseline]\n",
    "imgs_context = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in imgs_context]\n",
    "\n",
    "# Define grid\n",
    "gs = gridspec.GridSpec(2, 6, width_ratios=[2, 5, 5, 5, 5, 5]) \n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Set up class names\n",
    "class_names = ['Baseline', 'Prefiltering']\n",
    "for i in range(2):\n",
    "    ax = plt.subplot(gs[i, 0])\n",
    "    ax.text(0.5, 0.5, class_names[i], ha='center', va='center', rotation='vertical', fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Display baseline images\n",
    "for i in range(5):\n",
    "    ax = plt.subplot(gs[0, i+1])\n",
    "    ax.imshow(imgs_baseline[i])\n",
    "    ax.axis('off')\n",
    "\n",
    "# Display context images\n",
    "for i in range(5):\n",
    "    ax = plt.subplot(gs[1, i+1])\n",
    "    ax.imshow(imgs_context[i])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.07, hspace=0.05)\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save in high quality in res/beforeafter\n",
    "fig.savefig('res/beforeafter/plot_revised.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Visualization of Precision faulty images'''\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "\n",
    "img1_path = 'res/precision_faulty/visualize_1GYNc35brG1DJCtFYWs8KA_right.png'\n",
    "img2_path = 'res/precision_faulty/visualize_0wLMkTJ7IaDz8mJm3uNeHg_right.png'\n",
    "img3_path = 'res/precision_faulty/visualize_-CD3qZk9zyeumBU_w7Yl5A_front.png'\n",
    "img4_path = 'res/precision_faulty/visualize_-ay7zopCWOrSjeUuirk91A_right.png'\n",
    "img5_path = 'res/precision_faulty/visualize__pjTmksYX5Vpgoqm_GSOKA_back.png'\n",
    "\n",
    "# Load images\n",
    "img1 = cv2.imread(img1_path)\n",
    "img2 = cv2.imread(img2_path)\n",
    "img3 = cv2.imread(img3_path)\n",
    "img4 = cv2.imread(img4_path)\n",
    "img5 = cv2.imread(img5_path)\n",
    "\n",
    "imgs = [img1, img2, img3, img4, img5]\n",
    "\n",
    "# Convert the images in imgs_baseline and imgs_context to RGB\n",
    "imgs = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in imgs]\n",
    "\n",
    "# Define grid\n",
    "gs = gridspec.GridSpec(1, 5) \n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Display baseline images\n",
    "for i, img in enumerate(imgs):\n",
    "    ax = plt.subplot(gs[0, i])\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.07, hspace=0.05)\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save in high quality in res/beforeafter\n",
    "fig.savefig('res/precision_faulty/plot.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import argparse\n",
    "import geopandas as gpd\n",
    "\n",
    "def get_ps_labels():\n",
    "\n",
    "    base_url = \"https://sidewalk-amsterdam.cs.washington.edu/v2/access/attributesWithLabels?lat1={}&lng1={}&lat2={}&lng2={}\" \n",
    "    \n",
    "    whole = (52.303, 4.8, 52.425, 5.05)\n",
    "    centrum_west = (52.364925, 4.87444, 52.388692, 4.90641)\n",
    "    test = (52.0, 4.0, 53.0, 5.0)\n",
    "\n",
    "    coords = test\n",
    "\n",
    "    url = base_url.format(*coords)\n",
    "\n",
    "    #label_dump = os.path.join(args.label_dump, 'attributesWithLabels')\n",
    "\n",
    "    try:\n",
    "        project_sidewalk_labels = json.load(open('res/attributesWithLabels', 'r'))\n",
    "    except Exception as e:\n",
    "        print(\"Couldn't load local dump\")\n",
    "        project_sidewalk_labels = requests.get(url.format(*coords)).json()\n",
    "        #json.dump(project_sidewalk_labels, open(label_dump, 'w'))\n",
    "\n",
    "    ps_labels_df = gpd.GeoDataFrame.from_features(project_sidewalk_labels['features'])\n",
    "    # Print length before filtering\n",
    "    print('Length of labels from attributesWithLabels API: ', len(ps_labels_df))\n",
    "\n",
    "    return ps_labels_df\n",
    "\n",
    "def get_xy_coords_ps_labels():\n",
    "    # Send a get call to this API: https://sidewalk-amsterdam-test.cs.washington.edu/adminapi/labels/cvMetadata\n",
    "    other_labels = requests.get('https://sidewalk-amsterdam.cs.washington.edu/adminapi/labels/cvMetadata').json()\n",
    "    other_labels_df = pd.DataFrame(other_labels)\n",
    "    print('Length raw labels from cvMetadata API (low quality) : ', len(other_labels_df))\n",
    "\n",
    "    return other_labels_df\n",
    "\n",
    "def visualize_labels(image_path, gt_points):\n",
    "    # Load the image\n",
    "    # Depending on the machine, the path might be different\n",
    "    # Try to load the image with and without the .jpg extension\n",
    "    try:\n",
    "        image = plt.imread(image_path + '.jpg')\n",
    "    except:\n",
    "        image = plt.imread(image_path)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "\n",
    "    for gt_point in gt_points:\n",
    "        ax.scatter(gt_point[1], gt_point[0], color='red', s=7)\n",
    "\n",
    "    # Set small tick labels\n",
    "    ax.tick_params(axis='both', which='both', labelsize=6)\n",
    "    # No ticks\n",
    "    ax.set_xticks([])\n",
    "\n",
    "    # Add legend for red points\n",
    "    ax.scatter([], [], color='red', s=8, label='Ground Truth')\n",
    "    ax.legend(prop={'size': 5})\n",
    "\n",
    "    # Remove axes\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Save the image\n",
    "    fig.savefig('res/example_pano_labels.png', dpi=300, bbox_inches='tight')\n",
    "    # Close the figure\n",
    "    plt.close(fig)\n",
    "\n",
    "def compute_label_coordinates(image_path, dataframe, pano_id):            \n",
    "\n",
    "    # Load panorama image\n",
    "    # Depending on the machine, the path might be different\n",
    "    # Try to load the image with and without the .jpg extension\n",
    "    try:\n",
    "        image = plt.imread(image_path + '.jpg')\n",
    "    except:\n",
    "        image = plt.imread(image_path)\n",
    "\n",
    "    # Find all the labels in the panorama\n",
    "    labels = dataframe[dataframe['gsv_panorama_id'] == pano_id]\n",
    "\n",
    "    labels_coords = []\n",
    "\n",
    "    # For each label, find its coordinates in the panorama\n",
    "    for index, row in labels.iterrows():\n",
    "        #print('Labels coming from panorama:', row['gsv_panorama_id'])\n",
    "        label_name = row['label_id']\n",
    "        image_width = row['pano_width']\n",
    "        image_height = row['pano_height']\n",
    "        sv_image_x = row['pano_x']\n",
    "        # Momentarily change the definition of sv_image_y. For now,\n",
    "        # sv_image_y is the offset w.r.t. the middle of the image\n",
    "        # which means that the real y coordinate is y = (image_width / 2) - sv_image_y\n",
    "        sv_image_y = row['pano_y']\n",
    "        #real_y = (image_height / 2) - sv_image_y\n",
    "\n",
    "        #print(f'Original image width: {image_width}, height: {image_height}')\n",
    "        #print(f'Original label {label_name} coordinates: {sv_image_x}, {sv_image_y}')\n",
    "        #print(f'Original label {label_name} with real y-coordinates' \\\n",
    "        #    f'({image_height}/2){sv_image_y}: {sv_image_x}, {real_y}')\n",
    "\n",
    "        # image_width : sv_image_x = my_pano_width : sv_pano_x\n",
    "        # sv_pano_x = (sv_image_x * my_pano_width) / image_width\n",
    "        sv_pano_x = int(sv_image_x*image.shape[1]/image_width)\n",
    "        sv_pano_y = int(sv_image_y*image.shape[0]/image_height)\n",
    "\n",
    "        #print(f'Scaled label {label_name} coordinates: {sv_pano_x}, {sv_pano_y} \\n')\n",
    "\n",
    "        # Visualize the point (sv_pano_x, sv_pano_y) on the image\n",
    "        #print(f'Label {label_name} coordinates: {sv_pano_x}, {sv_pano_y} \\n')\n",
    "        #plt.scatter(sv_pano_x, sv_pano_y, color='red', s=10)\n",
    "\n",
    "        labels_coords.append((sv_pano_y, sv_pano_x))\n",
    "\n",
    "    return labels_coords\n",
    "\n",
    "def reorient_point(point, img_size, heading):\n",
    "    # We select a tolerance of 0.1 degrees so that \n",
    "    # the point is not reoriented if the heading is close to 0\n",
    "    tolerance = 0.1\n",
    "    if abs(heading) <= tolerance:\n",
    "        return point\n",
    "\n",
    "    else:\n",
    "        # Reshift point according to heading\n",
    "        shift = heading / 360\n",
    "        pixel_split = int(img_size[0] * shift)\n",
    "        \n",
    "        y, x = point\n",
    "        new_x = (x - pixel_split) % img_size[0]\n",
    "\n",
    "        reoriented_point = (y, new_x)\n",
    "        \n",
    "        return reoriented_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get Project Sidewalk labels from API\n",
    "ps_labels_df = get_ps_labels()\n",
    "# Get the labels from another API endpoint\n",
    "other_labels_df = get_xy_coords_ps_labels()\n",
    "\n",
    "# Filter other_labels_df to only contain obstacles ('label_type_id' == 3)\n",
    "other_labels_df = other_labels_df[other_labels_df['label_type_id'] == 3]\n",
    "\n",
    "print(f'Number of obstacles labels from cvMetadata API (low quality): {len(other_labels_df)}')\n",
    "\n",
    "# Intersect other_labels_df with ps_labels_df\n",
    "other_labels_df = other_labels_df[other_labels_df['label_id'].isin(ps_labels_df['label_id'])]\n",
    "print(f'Number of obstacles labels in other_labels_df after filtering for high quality data: {len(other_labels_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print the labels associated with 'pano_id' value: -RHS-ZYDt0sCDy2aS4AwOQ\n",
    "labels = other_labels_df[other_labels_df['gsv_panorama_id'] == '-RHS-ZYDt0sCDy2aS4AwOQ']\n",
    "\n",
    "# Load image\n",
    "img_path = 'res/-RHS-ZYDt0sCDy2aS4AwOQ.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "# Take the size of the image\n",
    "img_size = img.shape[:2]\n",
    "\n",
    "heading = 251.48272705078125\n",
    "\n",
    "# Compute the coordinate of the labels in the image\n",
    "labels_coords = compute_label_coordinates(img_path, other_labels_df, '-RHS-ZYDt0sCDy2aS4AwOQ')\n",
    "\n",
    "reoriented_labels_coords = []\n",
    "for label in labels_coords:\n",
    "    print('Initial coordinates of the label:', label)\n",
    "    # Reorient the point according to the heading\n",
    "    new_coords = reorient_point(label, img_size, heading)\n",
    "    print('New coordinates: ', new_coords)\n",
    "    reoriented_labels_coords.append(new_coords)\n",
    "\n",
    "visualize_labels(img_path, labels_coords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create some fake masks of random shapes\n",
    "mask1 = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "mask1[100:200, 100:200] = 255\n",
    "mask2 = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "mask2[300:400, 300:400] = 255\n",
    "mask3 = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "mask3[500:600, 500:600] = 255\n",
    "\n",
    "# Create areas and centroids for the masks based on the fake masks\n",
    "area1 = np.sum(mask1 == 255)\n",
    "area2 = np.sum(mask2 == 255)\n",
    "area3 = np.sum(mask3 == 255)\n",
    "\n",
    "centroid1 = np.array([150, 150])\n",
    "centroid2 = np.array([350, 350])\n",
    "centroid3 = np.array([550, 550])\n",
    "\n",
    "# Create a fake bbox (inside an image of size 1024x1024)\n",
    "fake_bbox = [5, 10, 150, 250]\n",
    "\n",
    "# Visualize the bbox and the masks on the black image\n",
    "img = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "img[fake_bbox[0]:fake_bbox[2], fake_bbox[1]:fake_bbox[3]] = 255\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the bbox and the masks on the same image (only one axis)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(img, cmap='gray')\n",
    "ax.imshow(mask1, cmap='jet', alpha=0.5)\n",
    "ax.imshow(mask2, cmap='jet', alpha=0.5)\n",
    "ax.imshow(mask3, cmap='jet', alpha=0.5)\n",
    "# Plot the centroids\n",
    "ax.scatter(centroid1[1], centroid1[0], color='red', s=10)\n",
    "ax.scatter(centroid2[1], centroid2[0], color='red', s=10)\n",
    "ax.scatter(centroid3[1], centroid3[0], color='red', s=10)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create a fake dictionary with the masks, areas, and centroids\n",
    "panos_info = {\n",
    "    'pano1': {\n",
    "        'face1': {\n",
    "            'masks': [mask1, mask2],\n",
    "            'areas': [area1, area2],\n",
    "            'centroids': [centroid1, centroid2]\n",
    "        },\n",
    "        'face2': {\n",
    "            'masks': [mask3],\n",
    "            'areas': [area3],\n",
    "            'centroids': [centroid3]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "data = [{ \"value\": 0, \"label\": \"background\"}, {\"value\": 1, \"label\": \"sidewalk\", \"logit\": 0.9, \"box\": fake_bbox}]\n",
    "\n",
    "# Create a new panos_info dictionary with the same structure as the original one\n",
    "new_panos_info = {}\n",
    "for pano_id in panos_info:\n",
    "    new_panos_info[pano_id] = {}\n",
    "    for face_idx in panos_info[pano_id]:\n",
    "        new_panos_info[pano_id][face_idx] = {\n",
    "            'masks': [],\n",
    "            'areas': [],\n",
    "            'centroids': []\n",
    "        }\n",
    "\n",
    "for pano_id in panos_info: \n",
    "    for face_idx in panos_info[pano_id]:\n",
    "        # Iterate over each mask in panos_info[pano_id][face_idx]['masks']\n",
    "        for mask, area, centroid in zip(panos_info[pano_id][face_idx]['masks'], panos_info[pano_id][face_idx]['areas'], panos_info[pano_id][face_idx]['centroids']):\n",
    "            # Iterate over each bounding box in data that has the label 'sidewalk'\n",
    "            # If there is no 'sidewalk' label, look for 'sidewalkroad' label\n",
    "            # If there are no 'sidewalk' or 'sidewalkroad' labels, skip the current face index\n",
    "            for d in data:\n",
    "                # d has the following structure: {\"value\", \"label\", \"logit\", \"box\": []}\n",
    "                # Iterate over the dictionary keys\n",
    "                if d.get('label') == 'sidewalk' or 'sidewalkroad':\n",
    "                    bbox = d.get('box')\n",
    "                    if bbox is None:\n",
    "                        continue\n",
    "                    bbox_mask = np.zeros((mask.shape))\n",
    "                    bbox_mask[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])] = 255\n",
    "                    if np.any(np.logical_and(mask, bbox_mask)):\n",
    "                        # Append the new mask, area, and centroid to the corresponding lists in the new_panos_info dictionary\n",
    "                        new_panos_info[pano_id][face_idx]['masks'].append(mask)\n",
    "                        new_panos_info[pano_id][face_idx]['areas'].append(area)\n",
    "                        new_panos_info[pano_id][face_idx]['centroids'].append(centroid)\n",
    "\n",
    "# Visualize the new masks\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(img, cmap='gray')\n",
    "for face_idx in new_panos_info['pano1']:\n",
    "    for mask, centroid in zip(new_panos_info['pano1'][face_idx]['masks'], new_panos_info['pano1'][face_idx]['centroids']):\n",
    "        ax.imshow(mask, cmap='jet', alpha=0.5)\n",
    "        ax.scatter(centroid[1], centroid[0], color='red', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Create some fake masks of random shapes\n",
    "mask1 = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "mask1[100:200, 100:200] = 255\n",
    "mask2 = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "mask2[300:400, 300:400] = 255\n",
    "mask3 = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "mask3[700:900, 700:900] = 255\n",
    "\n",
    "# Create an empty image\n",
    "img = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "\n",
    "# Create areas and centroids for the masks based on the fake masks\n",
    "area1 = np.sum(mask1 == 255)\n",
    "area2 = np.sum(mask2 == 255)\n",
    "area3 = np.sum(mask3 == 255)\n",
    "\n",
    "centroid1 = np.array([150, 150])\n",
    "centroid2 = np.array([350, 350])\n",
    "centroid3 = np.array([800, 800])\n",
    "\n",
    "# Create a big fake mask (inside an image of size 1024x1024)\n",
    "fake_mask = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "fake_mask[100:600, 100:600] = 255\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the bbox and the masks on the same image (only one axis)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(img, cmap='gray')\n",
    "ax.imshow(fake_mask, cmap='jet', alpha=0.8)\n",
    "ax.imshow(mask1, cmap='jet', alpha=0.5)\n",
    "ax.imshow(mask2, cmap='jet', alpha=0.5)\n",
    "ax.imshow(mask3, cmap='jet', alpha=0.5)\n",
    "# Plot the centroids\n",
    "ax.scatter(centroid1[1], centroid1[0], color='red', s=10)\n",
    "ax.scatter(centroid2[1], centroid2[0], color='red', s=10)\n",
    "ax.scatter(centroid3[1], centroid3[0], color='red', s=10)\n",
    "plt.show()\n",
    "\n",
    "# Create a fake dictionary with the masks, areas, and centroids\n",
    "panos_info = {\n",
    "    'pano1': {\n",
    "        'face1': {\n",
    "            'masks': [mask1, mask2],\n",
    "            'areas': [area1, area2],\n",
    "            'centroids': [centroid1, centroid2]\n",
    "        },\n",
    "        'face2': {\n",
    "            'masks': [mask3],\n",
    "            'areas': [area3],\n",
    "            'centroids': [centroid3]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create a new panos_info dictionary with the same structure as the original one\n",
    "new_panos_info = {}\n",
    "for pano_id in panos_info:\n",
    "    new_panos_info[pano_id] = {}\n",
    "    for face_idx in panos_info[pano_id]:\n",
    "        new_panos_info[pano_id][face_idx] = {\n",
    "            'masks': [],\n",
    "            'areas': [],\n",
    "            'centroids': []\n",
    "        }\n",
    "\n",
    "for pano_id in panos_info: \n",
    "    for face_idx in panos_info[pano_id]:\n",
    "        # Iterate over each mask in panos_info[pano_id][face_idx]['masks']\n",
    "        for mask, area, centroid in zip(panos_info[pano_id][face_idx]['masks'], panos_info[pano_id][face_idx]['areas'], panos_info[pano_id][face_idx]['centroids']):\n",
    "            print(f'Processing mask with area {area}')\n",
    "            # Compute the minimum distance between the centroid of the mask and the fake_mask\n",
    "            min_distance = np.min(cdist([centroid], np.argwhere(fake_mask == 255)))\n",
    "            \n",
    "            if min_distance < 50:\n",
    "                # Append the new mask, area, and centroid to the corresponding lists in the new_panos_info dictionary\n",
    "                new_panos_info[pano_id][face_idx]['masks'].append(mask)\n",
    "                new_panos_info[pano_id][face_idx]['areas'].append(area)\n",
    "                new_panos_info[pano_id][face_idx]['centroids'].append(centroid)\n",
    "            else:\n",
    "                # If there are no 'sidewalk' or 'sidewalkroad' labels, copy\n",
    "                # the masks, areas, and centroids from panos_info to new_panos_info\n",
    "                print('No sidewalk or sidewalkroad labels found. Skipping...')\n",
    "                #new_panos_info[pano_id][face_idx]['masks'] = panos_info[pano_id][face_idx]['masks']\n",
    "                #new_panos_info[pano_id][face_idx]['areas'] = panos_info[pano_id][face_idx]['areas']\n",
    "                #new_panos_info[pano_id][face_idx]['centroids'] = panos_info[pano_id][face_idx]['centroids']\n",
    "\n",
    "# Visualize the new masks\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(img, cmap='gray')\n",
    "for face_idx in new_panos_info['pano1']:\n",
    "    for mask, centroid in zip(new_panos_info['pano1'][face_idx]['masks'], new_panos_info['pano1'][face_idx]['centroids']):\n",
    "        ax.imshow(mask, cmap='jet', alpha=0.5)\n",
    "        ax.scatter(centroid[1], centroid[0], color='red', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(original_size, new_size):\n",
    "    # Function that calculates the scaling factor to resize the masks\n",
    "    return new_size / original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib import patches\n",
    "\n",
    "# Load pano\n",
    "pano_path = '/var/scratch/lombardo/download_PS/reprojected/KE2eBXFqUMUn49kvWjsCqA/left.png'\n",
    "pano = cv2.imread(pano_path, cv2.IMREAD_COLOR)\n",
    "pano = cv2.cvtColor(pano, cv2.COLOR_BGR2RGB)\n",
    "# Resize pano to 2310\n",
    "#pano = cv2.resize(pano, (2310, 2310))\n",
    "original_size = 2310\n",
    "new_size = 1024\n",
    "# Visualize pano\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(pano)\n",
    "\n",
    "\n",
    "# Load bbox\n",
    "bbox_path = '/var/scratch/lombardo/download_PS/segmented_B_0.25/KE2eBXFqUMUn49kvWjsCqA/mask_left.json'\n",
    "with open(bbox_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize bbox_mask\n",
    "bbox_mask = np.zeros((new_size, new_size))\n",
    "\n",
    "# Iterate over each bounding box in data that has the label 'sidewalk'\n",
    "# If there is no 'sidewalk' label, look for 'sidewalkroad' label\n",
    "# If there are no 'sidewalk' or 'sidewalkroad' labels, skip the current face index\n",
    "for d in data:\n",
    "    #print(f'Label: {d.get(\"label\")}')\n",
    "    # d has the following structure: {\"value\", \"label\", \"logit\", \"box\": []}\n",
    "    # Iterate over the dictionary keys\n",
    "    if d.get('label') in ['sidewalk', 'sidewalkroad']:\n",
    "        #print(f'bbox: {d.get(\"box\")}')\n",
    "        sidewalk_found = True\n",
    "        bbox = d.get('box')\n",
    "\n",
    "        # Scale the bbox\n",
    "        #scale_factor = scale(args.sidewalk_mask_size, args.size)\n",
    "        #bbox = [x * scale_factor for x in bbox]\n",
    "\n",
    "        #print(f'bbox: {bbox}')\n",
    "\n",
    "        # Add the current bbox to the bbox_mask\n",
    "        bbox_mask[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])] = 255\n",
    "\n",
    "centroid = [1000.80615098, 1008.17183131]\n",
    "# Dilate the centroid to make a mask of radius 10\n",
    "centroid_mask = np.zeros((new_size, new_size))\n",
    "centroid_mask[int(centroid[1]) - 10:int(centroid[1]) + 10, int(centroid[0]) - 10:int(centroid[0]) + 10] = 255\n",
    "\n",
    "intersection = cv2.bitwise_and(centroid_mask, bbox_mask)\n",
    "if np.count_nonzero(intersection) > 0:\n",
    "    print('There is an intersection')\n",
    "else:\n",
    "    print('There is no intersection')\n",
    "\n",
    "# Visualize bbox_mask on top of pano\n",
    "ax.imshow(bbox_mask, cmap='jet', alpha=0.5)\n",
    "ax.imshow(centroid_mask, cmap='jet', alpha=0.5)\n",
    "ax.scatter(centroid[1], centroid[0], color='red', s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "# Load mask\n",
    "mask_path = '/var/scratch/lombardo/download_PS/segmented_B_0.25/-2uB6480IX2sxmwnAnlLiA/sidewalk_mask_back.jpg'\n",
    "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "# Resize mask to 1024x1024\n",
    "mask = cv2.resize(mask, (1024, 1024))\n",
    "\n",
    "# Make the mask binary (0 or 255) using a threshold of 127\n",
    "# Threshold the image\n",
    "_, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "centroid = [550.80615098, 908.17183131]\n",
    "\n",
    "# Compute the minimum distance between centroid and mask \n",
    "centroid = np.array(centroid)\n",
    "\n",
    "# Reshape the centroid array to have two dimensions\n",
    "array_centroid = np.array(centroid).reshape(1, -1)\n",
    "\n",
    "# Compute the minimum distance between the centroid of the mask and the fake_mask\n",
    "min_distance = np.min(cdist(array_centroid, np.argwhere(mask == 255)))\n",
    "\n",
    "print(min_distance)\n",
    "\n",
    "\n",
    "# Show both centroid and mask in a single plot, along with the distance (min_distance)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(mask, cmap='gray')\n",
    "ax.scatter(centroid[1], centroid[0], color='red', s=10)\n",
    "ax.set_title(f'Min distance: {min_distance}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask_path = '/var/scratch/lombardo/download_PS/segmented_B_0.25/MmG7bzbVlHJDCIuMNinV9g/sidewalkroad_mask_right.jpg'\n",
    "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "# Resize mask to 1024x1024\n",
    "mask = cv2.resize(mask, (1024, 1024))\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(mask, cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of bboxes and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input_coco_format .json file \n",
    "import json\n",
    "#json_path = '/var/scratch/lombardo/download_PS/masks_resized_100_sidewalk_masks/input_coco_format_100.json'\n",
    "json_path = '/var/scratch/lombardo/download_PS/masks_resized_100_bboxes_fb1/input_coco_format_100.json'\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "unique_panos = len(set([pano['pano_id'] for pano in data]))\n",
    "\n",
    "print(f'Number of unique panos: {unique_panos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_faces(index):\n",
    "    # Function that maps the face index to the corresponding face\n",
    "    # Mapping: 0F 1R 2B 3L 4U 5D\n",
    "    # For example: index == 0, return 'front'\n",
    "    if index == 0:\n",
    "        return 'front'\n",
    "    elif index == 1:\n",
    "        return 'right'\n",
    "    elif index == 2:\n",
    "        return 'back'\n",
    "    elif index == 3:\n",
    "        return 'left'\n",
    "    elif index == 4:\n",
    "        return 'top'\n",
    "    elif index == 5:\n",
    "        return 'bottom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.ops import box_iou\n",
    "import pycocotools.mask as mask_util\n",
    "\n",
    "def get_bbox(mask):\n",
    "    \"\"\"Function to convert a mask to a bounding box.\"\"\"\n",
    "    pos = np.where(mask)\n",
    "    xmin = np.min(pos[1])\n",
    "    xmax = np.max(pos[1])\n",
    "    ymin = np.min(pos[0])\n",
    "    ymax = np.max(pos[0])\n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "def visualize(pano_id, face_idx, masks, bboxes):\n",
    "    # Load image\n",
    "    image_path = f'/var/scratch/lombardo/download_PS/reprojected/{pano_id}/{map_faces(face_idx)}.png'\n",
    "    image = cv2.imread(image_path)\n",
    "    # Load masks\n",
    "    for mask_dict in masks:\n",
    "        rle = mask_dict['segmentation']\n",
    "        pred_mask = mask_util.decode(rle)\n",
    "        pred_bbox = get_bbox(pred_mask)\n",
    "        # Draw bbox. Format: [xmin, ymin, xmax, ymax]\n",
    "        cv2.rectangle(image, (pred_bbox[0], pred_bbox[1]), (pred_bbox[2], pred_bbox[3]), (0, 255, 0), 2)\n",
    "    # Load bboxes. Format: [xmin, ymin, xmax, ymax]\n",
    "    for bbox in bboxes:\n",
    "        cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 0, 0), 2)\n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "    # Show the image\n",
    "    plt.show()\n",
    "\n",
    "def best_iou(pred_masks, bboxes):\n",
    "    best_ious = []\n",
    "    best_mask_indices = []\n",
    "    bboxes_indices = []\n",
    "\n",
    "    for bbox_idx, bbox in enumerate(bboxes):\n",
    "        gt_bbox = torch.tensor([bbox], dtype=torch.float)\n",
    "\n",
    "        max_iou = -1\n",
    "        best_mask_idx = -1\n",
    "\n",
    "        for mask_idx, mask_dict in enumerate(pred_masks):\n",
    "            rle = mask_dict['segmentation']\n",
    "            pred_mask = mask_util.decode(rle)\n",
    "            pred_bbox = get_bbox(pred_mask)\n",
    "            if pred_bbox is None:\n",
    "                continue\n",
    "            pred_bbox = torch.tensor([pred_bbox], dtype=torch.float)\n",
    "\n",
    "            # Calculate IoU using PyTorch function\n",
    "            iou = box_iou(gt_bbox, pred_bbox).item()\n",
    "\n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "                best_mask_idx = mask_idx\n",
    "\n",
    "        best_ious.append(max_iou)\n",
    "        best_mask_indices.append(best_mask_idx)\n",
    "        bboxes_indices.append(bbox_idx)\n",
    "\n",
    "    return best_ious, best_mask_indices, bboxes_indices\n",
    "\n",
    "def evaluate_single_face(masks, bboxes):\n",
    "    '''Access the list of dictionaries masks for the current pano and face. The structure is the following:\n",
    "    masks = [\n",
    "                {\n",
    "                'pano_id': 'pano_id_0',\n",
    "                'face_idx': 'face_idx_0',\n",
    "                'area': 'area',\n",
    "                'centroid': [x, y],\n",
    "                'segmentation': {\n",
    "                    'size': [height, width],\n",
    "                    'counts': 'RLE'\n",
    "                    },\n",
    "                },\n",
    "                {...}, {...}, ...\n",
    "            ]\n",
    "    '''\n",
    "    pano_id = masks[0]['pano_id']\n",
    "    face_idx = masks[0]['face_idx']\n",
    "    print(f\"Number of bboxes: {len(bboxes)}\")\n",
    "    n_masks = len(masks)\n",
    "    print(f'Number of masks: {n_masks}')\n",
    "    \n",
    "    # Compute metrics\n",
    "    # IoU\n",
    "    best_ious, mask_indices_iou, bboxes_indices_iou = best_iou(masks, bboxes)\n",
    "\n",
    "    '''Structure of the output dictionary:\n",
    "        results = {\n",
    "                    'pano_id_0': {\n",
    "                        'face_idx_0': {\n",
    "                            'closest_points': {\n",
    "                                'metrics': {\n",
    "                                    'distances': [],\n",
    "                                    'precision': [],\n",
    "                                    'recall': [],\n",
    "                                    'f1': [],\n",
    "                                    'average_precision': [],\n",
    "                                },\n",
    "                                'points': [],\n",
    "                                'indices': {\n",
    "                                    'mask_indices': [],\n",
    "                                    'gt_indices': []\n",
    "                                }\n",
    "                            },\n",
    "                            'anchor_points': {\n",
    "                                'metrics': {\n",
    "                                    'distances': [],\n",
    "                                    'precision': [],\n",
    "                                    'recall': [],\n",
    "                                    'f1': [],\n",
    "                                    'average_precision': [],\n",
    "                                },\n",
    "                                'points': [],\n",
    "                                'indices': {\n",
    "                                    'mask_indices': [],\n",
    "                                    'gt_indices': []\n",
    "                                }\n",
    "                            },\n",
    "                            'iou_metrics': {\n",
    "                                'best_ious': [],\n",
    "                                'ap_50': [],\n",
    "                                'ap_75': []\n",
    "                            },\n",
    "                            'iou_indices': {\n",
    "                                'mask_indices': [],\n",
    "                                'gt_indices': []\n",
    "                            }\n",
    "                        },\n",
    "                        'face_idx_1': {...},\n",
    "                    },\n",
    "                    'pano_id_1': {...}\n",
    "                }'''\n",
    "    # Return the metrics, points, and indices\n",
    "    return best_ious, mask_indices_iou, bboxes_indices_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load masks from .json file\n",
    "'''The panos_info dictionary will have the following structure:\n",
    "    panos_info = [\n",
    "            {\n",
    "            'pano_id': {\n",
    "                'face_idx': {\n",
    "                    'masks': [...],\n",
    "                    'areas': [...],\n",
    "                    'centroids': [...]\n",
    "                },\n",
    "                ...\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "    ]'''\n",
    "json_path = os.path.join('/var/scratch/lombardo/download_PS/masks_resized_100', 'input_coco_format_100.json')\n",
    "with open(json_path) as f:\n",
    "    panos_info = json.load(f)\n",
    "\n",
    "# Load bboxes from .csv file\n",
    "bboxes = pd.read_csv(os.path.join('/var/scratch/lombardo/download_PS/bboxes.csv'))\n",
    "\n",
    "# Count number of unique panos (pano is a dictionary)\n",
    "pano_ids = set(pano['pano_id'] for pano in panos_info)\n",
    "num_panoramas = len(pano_ids)\n",
    "print(f'Number of panos: {num_panoramas}')\n",
    "# Count number of masks (panos_info['pano_id']['face_idx']['masks'])\n",
    "print(f'Number of masks: {len(panos_info)}')\n",
    "# Count number of panos with bounding boxes\n",
    "bboxes_annotations = os.listdir('/var/scratch/lombardo/download_PS/annotations')\n",
    "print(f'Number of bounding boxes: {len(bboxes_annotations)}')\n",
    "\n",
    "'''The structure of grouped_panos will be:\n",
    "grouped_panos = {\n",
    "    'pano_id_0': {\n",
    "        'face_idx_0': [\n",
    "            {\n",
    "                'pano_id': 'pano_id_0',\n",
    "                'face_idx': 'face_idx_0',\n",
    "                'area': 'area',\n",
    "                'centroid': [x, y],\n",
    "                'segmentation': {\n",
    "                    'size': [height, width],\n",
    "                    'counts': 'RLE'\n",
    "                    },\n",
    "            },\n",
    "            {...},\n",
    "            ...\n",
    "        ]\n",
    "        'face_idx_1': [...],\n",
    "        ...\n",
    "    },\n",
    "    'pano_id_1': {}\n",
    "    ...\n",
    "}'''\n",
    "grouped_panos = {}\n",
    "for pano in panos_info:\n",
    "    pano_id = pano['pano_id']\n",
    "    face_idx = pano['face_idx']\n",
    "\n",
    "    if pano_id not in grouped_panos:\n",
    "        grouped_panos[pano_id] = {}\n",
    "\n",
    "    if face_idx not in grouped_panos[pano_id]:\n",
    "        grouped_panos[pano_id][face_idx] = []\n",
    "\n",
    "    grouped_panos[pano_id][face_idx].append(pano)\n",
    "\n",
    "# Evaluate each panorama's masks\n",
    "# Save results in a dictionary\n",
    "results = {} # for each face\n",
    "mean_results = {} # for each pano\n",
    "\n",
    "empty_panos = []\n",
    "\n",
    "pano_counter = 0\n",
    "for pano_id in tqdm(grouped_panos):\n",
    "\n",
    "    if pano_id not in results:\n",
    "        results[pano_id] = {}\n",
    "\n",
    "    if pano_id in bboxes_annotations:\n",
    "        print(f'Processing pano {pano_id}:')\n",
    "        for face_idx in grouped_panos[pano_id]:\n",
    "            print(f'Number of masks for face {face_idx}: {len(grouped_panos[pano_id][face_idx])}')\n",
    "            # Print number of bboxes for this pano and face\n",
    "            # The structure of bboxes is a PD dataframe with the following columns: pano_id, face_idx, bboxes\n",
    "            # The column bboxes contains a list of bboxes for each pano: [[xmin,ymin,xmax,ymax], [], ...]\n",
    "            bboxes_face = bboxes[(bboxes['pano_id'] == pano_id) & (bboxes['face_idx'] == face_idx)]['bboxes'].values[0]\n",
    "            # The problem is that bboxes_face is a string, not a list\n",
    "            # Convert it to a list\n",
    "            bboxes_face = eval(bboxes_face)\n",
    "            # Convert the string inside the list to float\n",
    "            bboxes_face = [[int(float(x)) for x in bbox] for bbox in bboxes_face]\n",
    "            print(f'Number of bboxes for face {face_idx}: {len(bboxes_face)}')\n",
    "\n",
    "            if len(bboxes_face) == 0:\n",
    "                print('The face does not contain obstacles.')\n",
    "                empty_panos.append((pano_id, face_idx))\n",
    "                break\n",
    "\n",
    "            for bbox in bboxes_face:\n",
    "                print(bbox)\n",
    "            \n",
    "            masks = grouped_panos[pano_id][face_idx]\n",
    "\n",
    "            if face_idx not in results[pano_id]:\n",
    "                results[pano_id][face_idx] = {}\n",
    "\n",
    "            a, b, c = evaluate_single_face(masks, bboxes_face)\n",
    "            print(f'Best IoU: {a}')\n",
    "            print(f'Mask Indices IoU: {b}')\n",
    "            print(f'Bboxes Indices IoU: {c}')\n",
    "\n",
    "            visualize(pano_id, face_idx, masks, bboxes_face)\n",
    "\n",
    "            pano_counter += 1\n",
    "            if pano_counter == 1:\n",
    "                break\n",
    "    if pano_counter == 1:\n",
    "        break\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare pipeline visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "# Load masks\n",
    "mask_path_baseline = '/var/scratch/lombardo/download_PS/masks_resized_100'\n",
    "mask_path_blacken = '/var/scratch/lombardo/download_PS/masks_blackened_100_resized_100'\n",
    "mask_path_bboxes = '/var/scratch/lombardo/download_PS/masks_resized_100_bboxes_fb1'\n",
    "mask_path_sidewalkmasks = '/var/scratch/lombardo/download_PS/masks_resized_100_sidewalk_masks_mind100_fb1'\n",
    "\n",
    "json_path_baseline = os.path.join(mask_path_baseline, 'input_coco_format_100.json')\n",
    "json_path_blacken = os.path.join(mask_path_blacken, 'input_coco_format_100.json')\n",
    "json_path_bboxes = os.path.join(mask_path_bboxes, 'input_coco_format_100.json')\n",
    "json_path_sidewalkmasks = os.path.join(mask_path_sidewalkmasks, 'input_coco_format_100.json')\n",
    "\n",
    "reprojected_blackened_path = '/var/scratch/lombardo/download_PS/reprojected_blackened_100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_panos_info(json_path):\n",
    "\n",
    "    with open(json_path) as f:\n",
    "        panos_info = json.load(f)\n",
    "\n",
    "    # Count number of unique panos (pano is a dictionary)\n",
    "    pano_ids = set(pano['pano_id'] for pano in panos_info)\n",
    "    num_panoramas = len(pano_ids)\n",
    "    print(f'Number of panos: {num_panoramas}')\n",
    "    # Count number of masks (panos_info['pano_id']['face_idx']['masks'])\n",
    "    print(f'Number of masks: {len(panos_info)}')\n",
    "\n",
    "    '''The structure of grouped_panos will be:\n",
    "    grouped_panos = {\n",
    "        'pano_id_0': {\n",
    "            'face_idx_0': [\n",
    "                {\n",
    "                    'pano_id': 'pano_id_0',\n",
    "                    'face_idx': 'face_idx_0',\n",
    "                    'area': 'area',\n",
    "                    'centroid': [x, y],\n",
    "                    'segmentation': {\n",
    "                        'size': [height, width],\n",
    "                        'counts': 'RLE'\n",
    "                        },\n",
    "                },\n",
    "                {...},\n",
    "                ...\n",
    "            ]\n",
    "            'face_idx_1': [...],\n",
    "            ...\n",
    "        },\n",
    "        'pano_id_1': {}\n",
    "        ...\n",
    "    }'''\n",
    "    grouped_panos = {}\n",
    "    for pano in panos_info:\n",
    "        pano_id = pano['pano_id']\n",
    "        face_idx = pano['face_idx']\n",
    "\n",
    "        if pano_id not in grouped_panos:\n",
    "            grouped_panos[pano_id] = {}\n",
    "\n",
    "        if face_idx not in grouped_panos[pano_id]:\n",
    "            grouped_panos[pano_id][face_idx] = []\n",
    "\n",
    "        grouped_panos[pano_id][face_idx].append(pano)\n",
    "\n",
    "    return grouped_panos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all masks\n",
    "grouped_panos_baseline = load_panos_info(json_path_baseline)\n",
    "grouped_panos_blacken = load_panos_info(json_path_blacken)\n",
    "grouped_panos_bboxes = load_panos_info(json_path_bboxes)\n",
    "grouped_panos_sidewalkmasks = load_panos_info(json_path_sidewalkmasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "reprojected_folder = '/var/scratch/lombardo/download_PS/reprojected'\n",
    "segmented_folder = '/var/scratch/lombardo/download_PS/segmented_B_0.25'\n",
    "algorithm_mapping = {\n",
    "    'baseline': grouped_panos_baseline,\n",
    "    'blacken': grouped_panos_blacken,\n",
    "    'bboxes': grouped_panos_bboxes,\n",
    "    'sidewalkmasks': grouped_panos_sidewalkmasks\n",
    "}\n",
    "\n",
    "# Randomize the order of the panos\n",
    "pano_ids = list(algorithm_mapping['baseline'].keys())  # Assumes same keys across all algorithms\n",
    "np.random.shuffle(pano_ids)\n",
    "for pano in pano_ids:\n",
    "    pano_id = pano\n",
    "    #pano_id = '_pjTmksYX5Vpgoqm_GSOKA'\n",
    "    #pano_id = '4w05JbqOnGLYHAt6zKDbZQ'\n",
    "    #pano_id = '0m9Or3xbo7JvO34d39YHSg'\n",
    "    #pano_id = '-NVzemAJVgKxPc5icSUDxw'\n",
    "    print(f'Pano: {pano_id}')\n",
    "\n",
    "    for face in ['front', 'back', 'left', 'right']:\n",
    "        #face = 'back'\n",
    "        #face = 'right'\n",
    "        #face = 'back'\n",
    "        face = 'front'\n",
    "        print(f'Face: {face}')\n",
    "\n",
    "        # Check if sidewalk mask exists\n",
    "        bboxes_path = os.path.join(segmented_folder, pano_id, f'mask_{face}.json')\n",
    "        with open(bboxes_path) as f:\n",
    "                bboxes_data = json.load(f)\n",
    "        exists_flag = False\n",
    "        for bbox_d in bboxes_data:\n",
    "            if bbox_d.get('label') == 'sidewalk':\n",
    "                exists_flag = True\n",
    "                break\n",
    "        if not exists_flag:\n",
    "            print('No sidewalk label found')\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "\n",
    "            for algorithm in ['baseline', 'blacken', 'bboxes', 'sidewalkmasks']:\n",
    "                print(f'Algorithm: {algorithm}')\n",
    "                grouped_panos = algorithm_mapping[algorithm]\n",
    "\n",
    "                # Find the reprojected image in the reprojected folder\n",
    "                if algorithm == 'blacken':\n",
    "                    image_path = os.path.join(reprojected_blackened_path, pano_id, face + '.png')\n",
    "                else:\n",
    "                    image_path = os.path.join(reprojected_folder, pano_id, face + '.png')\n",
    "                \n",
    "                image = cv2.imread(image_path)\n",
    "                # Convert to RGB\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # Load the semantic segmentation results in segmented_folder/pano_id/sidewalk_mask_{face}.jpg'\n",
    "                sidewalk_mask_path = os.path.join(segmented_folder, pano_id, 'sidewalk_mask_' + face + '.jpg')\n",
    "                # Open the sidewalk mask\n",
    "                size = 1024\n",
    "                sidewalk_mask = cv2.imread(sidewalk_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                sidewalk_mask = cv2.resize(sidewalk_mask, (size, size))\n",
    "                _, sidewalk_mask = cv2.threshold(sidewalk_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "                # Prepare overlay with semantic segmentation results\n",
    "                semseg_image_copy = image.copy()\n",
    "                # Overlay sidewalk mask and bbox with transparency of 0.5\n",
    "                semseg_image_copy[sidewalk_mask == 255] = (semseg_image_copy[sidewalk_mask == 255] * 0.5 + np.array([255, 255, 255]) * 0.5).astype(np.uint8)\n",
    "\n",
    "                # Initialize bbox_mask\n",
    "                bbox_mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "                for bbox_d in bboxes_data:\n",
    "                    #if bbox_d.get('label') in ['sidewalk', 'sidewalkroad']:\n",
    "                    if bbox_d.get('label') in ['sidewalk']:\n",
    "                        print(bbox_d.get('label'))\n",
    "                        bbox = bbox_d.get('box')\n",
    "                        cv2.rectangle(bbox_mask, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), 255, 2)\n",
    "                        cv2.rectangle(semseg_image_copy, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 160, 0), 3)\n",
    "\n",
    "                # First for white masks, second for colored masks\n",
    "                #object_masks = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "                object_masks = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "                \n",
    "                face_idx = reverse_map_faces(face)\n",
    "\n",
    "                for masks_face_idx, masks_list in grouped_panos[pano_id].items():\n",
    "                    if masks_face_idx == int(face_idx):\n",
    "                        for idx, mask_dict in enumerate(masks_list):\n",
    "                            rle = mask_dict['segmentation']\n",
    "                            mask = mask_util.decode(rle)\n",
    "                            color = [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
    "                            #object_masks[mask == 1] = 255\n",
    "                            object_masks[mask == 1] = color\n",
    "\n",
    "                # Image copy\n",
    "                image_copy = image.copy()\n",
    "                # Overlay object_masks with transparency of 0.3\n",
    "                image_copy[object_masks == 255] = (image_copy[object_masks == 255] * 0.5 + np.array([255, 255, 255]) * 0.5).astype(np.uint8)\n",
    "\n",
    "                # Visualize the image, the sidewalk mask and the bbox mask using matplotlib\n",
    "                #fig, ax = plt.subplots(1, 5, figsize=(15, 15))\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "                ax[0].imshow(image)\n",
    "                #ax[1].imshow(sidewalk_mask)\n",
    "                ax[1].imshow(semseg_image_copy)\n",
    "                #ax[2].imshow(bbox_mask)\n",
    "                #ax[3].imshow(object_masks)\n",
    "                #ax[4].imshow(image_copy)\n",
    "                ax[2].imshow(image_copy)\n",
    "                for a in ax:\n",
    "                    a.set_xticks([])\n",
    "                    a.set_yticks([])\n",
    "                plt.show()\n",
    "\n",
    "                # Save everything\n",
    "                #if algorithm == 'blacken':\n",
    "                    #cv2.imwrite(f'res/pipeline/{pano_id}_{face}_reprojected.png', cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                #cv2.imwrite(f'res/pipeline/{pano_id}_{face}_{algorithm}_semseg.png', cv2.cvtColor(semseg_image_copy, cv2.COLOR_BGR2RGB))\n",
    "                #cv2.imwrite(f'res/pipeline/{pano_id}_{face}_{algorithm}_results.png', cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB))\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input images for pipeline visualization\n",
    "\n",
    "# Load image from 'res/equirectangular.png'\n",
    "reoriented_folder = '/var/scratch/lombardo/download_PS/reoriented'\n",
    "img_path = os.path.join(reoriented_folder, '-NVzemAJVgKxPc5icSUDxw.jpg')\n",
    "reoriented_img = cv2.imread(img_path)\n",
    "\n",
    "# Convert to cubemap\n",
    "cubemap = py360convert.e2c(reoriented_img, face_w=1024)\n",
    "# Print dtype of cubemap\n",
    "print(cubemap.dtype)\n",
    "# Flip horizontally the images of cubemap at indices 0 and 2\n",
    "#cubemap[[0,2]] = cubemap[[0,2]][:,::-1]\n",
    "# Save cubemap as example_pano_triangle_cb.png\n",
    "cv2.imwrite('res/pipeline_reoriented_cubemap.jpg', cubemap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_labels(args, faces, pano_id, masks, labels_df, directory):\n",
    "\n",
    "    for face_idx in faces:\n",
    "        # Reverse map the face index to the face name\n",
    "        face = map_faces(int(face_idx))\n",
    "\n",
    "        # Check if we already processed this face\n",
    "        output_path = os.path.join(directory, f'visualize_{pano_id}_{face}.png')\n",
    "        if os.path.exists(output_path):\n",
    "            continue\n",
    "\n",
    "        fig = plt.figure()\n",
    "        # Load the face\n",
    "        face_path = os.path.join(args.input_dir, pano_id, f'{face}.png')\n",
    "        img = cv2.imread(face_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img)\n",
    "\n",
    "        # Traverse the masks in masks_list, decode them and load each of them with a different color\n",
    "        output_mask = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "        for masks_face_idx, masks_list in masks.items():\n",
    "            if masks_face_idx == int(face_idx):\n",
    "                for idx, mask_dict in enumerate(masks_list):\n",
    "                    rle = mask_dict['segmentation']\n",
    "                    mask = mask_util.decode(rle)\n",
    "                    color = [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
    "                    output_mask[mask == 1] = color\n",
    "\n",
    "        # Plot the mask\n",
    "        plt.imshow(output_mask, alpha=0.4)\n",
    "        #mask_path = os.path.join(args.masks_dir, pano_id, f'{face}.png')\n",
    "        #mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        #plt.imshow(mask, alpha=0.5, cmap='gray')\n",
    "\n",
    "        # Load ground truth points knowing that the coordinates are (reprojected_pano_y,reprojected_pano_x)\n",
    "        gt_points = []\n",
    "        for idx, row in labels_df.iterrows():\n",
    "                if row['gsv_panorama_id'] == pano_id.replace(\"'\", \"\") and row['face_idx'] == int(face_idx):\n",
    "                    gt_points.append([row['reprojected_pano_y'], row['reprojected_pano_x']])\n",
    "\n",
    "        for gt_point in gt_points:\n",
    "            plt.scatter(gt_point[1], gt_point[0], color='red', s=7)\n",
    "\n",
    "        # Set small tick labels\n",
    "        plt.tick_params(axis='both', which='both', labelsize=6)\n",
    "\n",
    "        # Add legend for red points\n",
    "        plt.scatter([], [], color='red', s=8, label='Ground Truth')\n",
    "        plt.legend(prop={'size': 5})\n",
    "\n",
    "        # Save the image\n",
    "        fig.savefig(os.path.join(directory, f'visualize_{pano_id}_{face}.png'), dpi=300, bbox_inches='tight')\n",
    "        # Close the figure\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "reprojected_folder = '/var/scratch/lombardo/download_PS/reprojected'\n",
    "segmented_folder = '/var/scratch/lombardo/download_PS/segmented_B_0.25'\n",
    "algorithm_mapping = {\n",
    "    'baseline': grouped_panos_baseline,\n",
    "    'blacken': grouped_panos_blacken,\n",
    "    'bboxes': grouped_panos_bboxes,\n",
    "    'sidewalkmasks': grouped_panos_sidewalkmasks\n",
    "}\n",
    "\n",
    "def save_subplot(ax, filename):\n",
    "    fig = plt.figure()\n",
    "    new_ax = fig.add_subplot(111, frame_on=False)\n",
    "    new_ax.xaxis.set_ticks([])\n",
    "    new_ax.yaxis.set_ticks([])\n",
    "    new_ax.set_xticklabels([])\n",
    "    new_ax.set_yticklabels([])\n",
    "    for i in range(len(ax.images)):\n",
    "        new_ax.imshow(ax.images[i].get_array(), alpha=ax.images[i].get_alpha(), cmap=ax.images[i].get_cmap())\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "# Randomize the order of the panos\n",
    "pano_ids = list(algorithm_mapping['baseline'].keys())  # Assumes same keys across all algorithms\n",
    "np.random.shuffle(pano_ids)\n",
    "for pano in pano_ids:\n",
    "    #pano_id = pano\n",
    "    #pano_id = '_pjTmksYX5Vpgoqm_GSOKA'\n",
    "    #pano_id = '4w05JbqOnGLYHAt6zKDbZQ'\n",
    "    #pano_id = '0m9Or3xbo7JvO34d39YHSg'\n",
    "    #pano_id = '-NVzemAJVgKxPc5icSUDxw'\n",
    "    #pano_id = '_IkbLqsPGpvTl3VC_QAugw'\n",
    "    pano_id = 'qHGj7xzo1LgCxDXyjtP_0g'\n",
    "    print(f'Pano: {pano_id}')\n",
    "\n",
    "    # Print the row of labels_reprojected that contains the pano_id in gsv_panorama_id\n",
    "    #print(labels_reprojected[labels_reprojected['gsv_panorama_id'] == pano_id.replace(\"'\", \"\")])\n",
    "\n",
    "    for face in ['front', 'back', 'left', 'right']:\n",
    "        #face = 'back'\n",
    "        #face = 'right'\n",
    "        #face = 'back'\n",
    "        #face = 'front'\n",
    "        print(f'Face: {face}')\n",
    "\n",
    "        # Check if sidewalk mask exists\n",
    "        bboxes_path = os.path.join(segmented_folder, pano_id, f'mask_{face}.json')\n",
    "        with open(bboxes_path) as f:\n",
    "                bboxes_data = json.load(f)\n",
    "        exists_flag = False\n",
    "        for bbox_d in bboxes_data:\n",
    "            if bbox_d.get('label') == 'sidewalk':\n",
    "                exists_flag = True\n",
    "                break\n",
    "        if not exists_flag:\n",
    "            print('No sidewalk label found')\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            face_idx = reverse_map_faces(face)\n",
    "\n",
    "            # Load ground truth labels\n",
    "            gt_points = []\n",
    "            for idx, row in labels_reprojected.iterrows():\n",
    "                    if row['gsv_panorama_id'] == pano_id.replace(\"'\", \"\") and row['face_idx'] == int(face_idx):\n",
    "                        gt_points.append([row['reprojected_pano_y'], row['reprojected_pano_x']])\n",
    "\n",
    "            #print(f'Number of gt_points: {len(gt_points)}')\n",
    "            #if len(gt_points) == 0:\n",
    "            #    break\n",
    "\n",
    "            # Find the reprojected image in the reprojected folder\n",
    "            image_path = os.path.join(reprojected_folder, pano_id, face + '.png')\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Convert to RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            # Load the semantic segmentation results in segmented_folder/pano_id/sidewalk_mask_{face}.jpg'\n",
    "            sidewalk_mask_path = os.path.join(segmented_folder, pano_id, 'sidewalk_mask_' + face + '.jpg')\n",
    "            # Open the sidewalk mask\n",
    "            size = 1024\n",
    "            sidewalk_mask = cv2.imread(sidewalk_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            sidewalk_mask = cv2.resize(sidewalk_mask, (size, size))\n",
    "            _, sidewalk_mask = cv2.threshold(sidewalk_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Prepare overlay with semantic segmentation results\n",
    "            semseg_image_copy = image.copy()\n",
    "            # Overlay sidewalk mask and bbox with transparency of 0.5\n",
    "            #semseg_image_copy[sidewalk_mask == 255] = (semseg_image_copy[sidewalk_mask == 255] * 0.5 + np.array([255, 255, 255]) * 0.5).astype(np.uint8)\n",
    "\n",
    "            semseg_mask = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "            color = [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
    "            #object_masks[mask == 1] = 255\n",
    "            semseg_mask[sidewalk_mask == 255] = color\n",
    "\n",
    "            # Initialize bbox_mask\n",
    "            bbox_mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "            for bbox_d in bboxes_data:\n",
    "                #if bbox_d.get('label') in ['sidewalk', 'sidewalkroad']:\n",
    "                if bbox_d.get('label') in ['sidewalk']:\n",
    "                    print(bbox_d.get('label'))\n",
    "                    bbox = bbox_d.get('box')\n",
    "                    cv2.rectangle(bbox_mask, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), 255, 2)\n",
    "                    cv2.rectangle(semseg_image_copy, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 160, 0), 3)\n",
    "\n",
    "            # Initialize figure\n",
    "            fig, ax = plt.subplots(1, 5, figsize=(15, 15))\n",
    "\n",
    "            # Show input\n",
    "            ax[0].imshow(image)\n",
    "            # Show semantic segmentation\n",
    "            ax[1].imshow(semseg_image_copy)\n",
    "            ax[1].imshow(semseg_mask, alpha=0.4)\n",
    "\n",
    "            if face == 'right':\n",
    "                save_subplot(ax[0], f'res/experiments/{pano_id}_{face}_0.png')\n",
    "                save_subplot(ax[1], f'res/experiments/{pano_id}_{face}_1.png')\n",
    "\n",
    "            counter = 2\n",
    "            for algorithm in ['baseline', 'bboxes', 'sidewalkmasks']:\n",
    "                print(f'Algorithm: {algorithm}')\n",
    "                grouped_panos = algorithm_mapping[algorithm]\n",
    "\n",
    "                # First for white masks, second for colored masks\n",
    "                #object_masks = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "                object_masks = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "                for masks_face_idx, masks_list in grouped_panos[pano_id].items():\n",
    "                    if masks_face_idx == int(face_idx):\n",
    "                        for idx, mask_dict in enumerate(masks_list):\n",
    "                            rle = mask_dict['segmentation']\n",
    "                            mask = mask_util.decode(rle)\n",
    "                            color = [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
    "                            #object_masks[mask == 1] = 255\n",
    "                            object_masks[mask == 1] = color\n",
    "\n",
    "                # Image copy\n",
    "                image_copy = image.copy()\n",
    "                # Overlay object_masks with transparency of 0.3\n",
    "                #image_copy[object_masks == 255] = (image_copy[object_masks == 255] * 0.5 + np.array([255, 255, 255]) * 0.5).astype(np.uint8)\n",
    "\n",
    "                # Visualize the image, the sidewalk mask and the bbox mask using matplotlib\n",
    "                #fig, ax = plt.subplots(1, 5, figsize=(15, 15))\n",
    "                \n",
    "                \n",
    "                #ax[2].imshow(bbox_mask)\n",
    "                #ax[3].imshow(object_masks)\n",
    "                #ax[4].imshow(image_copy)\n",
    "                ax[counter].imshow(image_copy)\n",
    "                ax[counter].imshow(object_masks, alpha=0.4)\n",
    "                \n",
    "                if face == 'right':\n",
    "                    save_subplot(ax[counter], f'res/experiments/{pano_id}_{face}_{algorithm}_{counter}.png')\n",
    "                \n",
    "                counter += 1\n",
    "\n",
    "            for a in ax:\n",
    "                a.set_xticks([])\n",
    "                a.set_yticks([])\n",
    "                '''for gt_point in gt_points:\n",
    "                    a.scatter(gt_point[1], gt_point[0], color='red', s=7)\n",
    "                    # Add legend for red points\n",
    "                    a.scatter([], [], color='red', s=8, label='Ground Truth')\n",
    "                    a.legend(prop={'size': 5})'''\n",
    "            plt.show()\n",
    "                   \n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiate performance by neighbourhood (Stadsdelen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import requests\n",
    "\n",
    "def fetch_pano_ids_from_webserver():\n",
    "    unique_ids = set()\n",
    "    pano_info = []\n",
    "    sidewalk_server_fqdn = \"sidewalk-amsterdam.cs.washington.edu\"\n",
    "    conn = http.client.HTTPSConnection(sidewalk_server_fqdn)\n",
    "    conn.request(\"GET\", \"/adminapi/panos\")\n",
    "    r1 = conn.getresponse()\n",
    "    data = r1.read()\n",
    "    jsondata = json.loads(data)\n",
    "\n",
    "    # Structure of JSON data\n",
    "    # [\n",
    "    #     {\n",
    "    #         \"gsv_panorama_id\": \"example-id\",\n",
    "    #         \"image_width\": 16384,\n",
    "    #         \"image_height\": 8192,\n",
    "    #         \"panorama_lat\": 52.315662,\n",
    "    #         \"panorama_lng\":4.9531154,\n",
    "    #         \"photographer_heading\":1.0355758,\n",
    "    #         \"photographer_pitch\":240.7730102\n",
    "    #     },\n",
    "    #     ...\n",
    "    # ]\n",
    "    for value in jsondata:\n",
    "        pano_id = value[\"gsv_panorama_id\"]\n",
    "        if pano_id not in unique_ids:\n",
    "            # Check if the pano_id is an empty string.\n",
    "            if pano_id and pano_id != 'tutorial':\n",
    "                unique_ids.add(pano_id)\n",
    "                pano_info.append(value)\n",
    "            else:\n",
    "                print(\"Pano ID is an empty string or is for tutorial\")\n",
    "        else:\n",
    "            print(\"Duplicate pano ID\")\n",
    "    assert len(unique_ids) == len(pano_info)\n",
    "    #print(\"Number of unique pano IDs: {}\".format(len(unique_ids)))\n",
    "    #print(pano_info[:10])\n",
    "    return pano_info\n",
    "\n",
    "pano_info = fetch_pano_ids_from_webserver()\n",
    "print(len(pano_info))\n",
    "\n",
    "regions = requests.get('https://maps.amsterdam.nl/open_geodata/geojson_lnglat.php?KAARTLAAG=INDELING_STADSDEEL&THEMA=gebiedsindeling').json()\n",
    "regions_df = gpd.GeoDataFrame.from_features(regions['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pano_info is a list of dictionaries with the following structure:\n",
    "# [\n",
    "#     {\n",
    "#         \"gsv_panorama_id\": \"example-id\",\n",
    "#         \"width\": 16384,\n",
    "#         \"height\": 8192,\n",
    "#         \"lat\": 52.315662,\n",
    "#         \"lng\": 4.9531154,\n",
    "#         ...\n",
    "#     },\n",
    "#     ...\n",
    "# ]\n",
    "# Filter from pano_info the pano_ids (gsv_panorama_id) that are NOT in the list of pano_ids\n",
    "filtered_pano_info = [p for p in pano_info if p['gsv_panorama_id'] in pano_ids]\n",
    "print(len(filtered_pano_info))\n",
    "# Make a dataframe out of gsv_panorama_id and lat, lng\n",
    "neighbourhood_df = pd.DataFrame(filtered_pano_info)[['gsv_panorama_id', 'lat', 'lng']]\n",
    "# Convert the dataframe to a geodataframe with a Point geometry POINT (lng lat)\n",
    "neighbourhood_gdf = gpd.GeoDataFrame(neighbourhood_df, geometry=gpd.points_from_xy(neighbourhood_df.lng, neighbourhood_df.lat))\n",
    "panos_with_neighbourhoods = gpd.sjoin(neighbourhood_gdf, regions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Stadsdeel to the results of different algorithms\n",
    "baseline_results_path = '/var/scratch/lombardo/download_PS/evaluation_100_100_100/mean_results.csv'\n",
    "blacken_results_path = '/var/scratch/lombardo/download_PS/evaluation_blackened_100_100_100_100/mean_results.csv'\n",
    "bboxes_results_path = '/var/scratch/lombardo/download_PS/evaluation_bboxes_100_100_100_fb1/mean_results.csv'\n",
    "sidewalkmasks_results_path = '/var/scratch/lombardo/download_PS/evaluation_masks_100_100_100_mind100_fb1/mean_results.csv'\n",
    "\n",
    "baseline_results = pd.read_csv(baseline_results_path)\n",
    "blacken_results = pd.read_csv(blacken_results_path)\n",
    "bboxes_results = pd.read_csv(bboxes_results_path)\n",
    "sidewalkmasks_results = pd.read_csv(sidewalkmasks_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataframe, add the column 'Stadsdeel' with the corresponding value (gsv_panorama_id == pano_id)\n",
    "baseline_results['Stadsdeel'] = baseline_results['pano_id'].map(panos_with_neighbourhoods.set_index('gsv_panorama_id')['Stadsdeel'])\n",
    "blacken_results['Stadsdeel'] = blacken_results['pano_id'].map(panos_with_neighbourhoods.set_index('gsv_panorama_id')['Stadsdeel'])\n",
    "bboxes_results['Stadsdeel'] = bboxes_results['pano_id'].map(panos_with_neighbourhoods.set_index('gsv_panorama_id')['Stadsdeel'])\n",
    "sidewalkmasks_results['Stadsdeel'] = sidewalkmasks_results['pano_id'].map(panos_with_neighbourhoods.set_index('gsv_panorama_id')['Stadsdeel'])\n",
    "\n",
    "# For each dataframe, group by Stadsdeel and compute the mean of the columns (excluding pano_id and stadsdeel)\n",
    "baseline_results_grouped = baseline_results.groupby('Stadsdeel').mean().reset_index()\n",
    "blacken_results_grouped = blacken_results.groupby('Stadsdeel').mean().reset_index()\n",
    "bboxes_results_grouped = bboxes_results.groupby('Stadsdeel').mean().reset_index()\n",
    "sidewalkmasks_results_grouped = sidewalkmasks_results.groupby('Stadsdeel').mean().reset_index()\n",
    "\n",
    "# Save in the corresponding path, a new csv file with the results grouped by Stadsdeel\n",
    "baseline_results_grouped.to_csv('/var/scratch/lombardo/download_PS/evaluation_100_100_100/mean_results_neighbourhood.csv', index=False)\n",
    "blacken_results_grouped.to_csv('/var/scratch/lombardo/download_PS/evaluation_blackened_100_100_100_100/mean_results_neighbourhood.csv', index=False)\n",
    "bboxes_results_grouped.to_csv('/var/scratch/lombardo/download_PS/evaluation_bboxes_100_100_100_fb1/mean_results_neighbourhood.csv', index=False)\n",
    "sidewalkmasks_results_grouped.to_csv('/var/scratch/lombardo/download_PS/evaluation_masks_100_100_100_mind100_fb1/mean_results_neighbourhood.csv', index=False)\n",
    "\n",
    "\n",
    "# Print how many panoramas are in each Stadsdeel\n",
    "print(baseline_results['Stadsdeel'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 'mean_cp_precision', 'mean_cp_recall', 'mean_cp_f1', 'mean_cp_ap' for each Stadsdeel of baseline_results_grouped\n",
    "print(baseline_results_grouped[['Stadsdeel', 'mean_cp_precision', 'mean_cp_recall', 'mean_cp_f1', 'mean_cp_ap']])\n",
    "\n",
    "# Show 'mean_cp_precision', 'mean_cp_recall', 'mean_cp_f1', 'mean_cp_ap' for each Stadsdeel of blacken_results_grouped\n",
    "print(blacken_results_grouped[['Stadsdeel', 'mean_cp_precision', 'mean_cp_recall', 'mean_cp_f1', 'mean_cp_ap']])\n",
    "\n",
    "# Show 'mean_cp_precision', 'mean_cp_recall', 'mean_cp_f1', 'mean_cp_ap' for each Stadsdeel of bboxes_results_grouped\n",
    "print(bboxes_results_grouped[['Stadsdeel', 'mean_cp_precision', 'mean_cp_recall', 'mean_cp_f1', 'mean_cp_ap']])\n",
    "\n",
    "# Show 'mean_cp_precision', 'mean_cp_recall', 'mean_cp_f1', 'mean_cp_ap' for each Stadsdeel of sidewalkmasks_results_grouped\n",
    "print(sidewalkmasks_results_grouped[['Stadsdeel', 'mean_cp_precision', 'mean_cp_recall', 'mean_cp_f1', 'mean_cp_ap']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 10 gsv_panorama_ids from different Stadsdeel\n",
    "\n",
    "path = '/var/scratch/lombardo/download_PS/reoriented/'\n",
    "\n",
    "# Open them as images\n",
    "# Make a fig with 10 images, 5 per row\n",
    "fig, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "for i, pano_id in enumerate(bboxes_results[bboxes_results['Stadsdeel'] == 'Centrum']['pano_id'].sample(10)):\n",
    "    pano = cv2.imread(os.path.join(path, pano_id + '.jpg'), cv2.IMREAD_COLOR)\n",
    "    ax[i//5, i%5].imshow(cv2.cvtColor(pano, cv2.COLOR_BGR2RGB))\n",
    "    ax[i//5, i%5].set_title(pano_id)\n",
    "    ax[i//5, i%5].axis('off')\n",
    "    # Tight layout\n",
    "    fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a fig with 10 images, 5 per row\n",
    "fig, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "for i, pano_id in enumerate(bboxes_results[bboxes_results['Stadsdeel'] == 'Noord']['pano_id'].sample(10)):\n",
    "    pano = cv2.imread(os.path.join(path, pano_id + '.jpg'), cv2.IMREAD_COLOR)\n",
    "    ax[i//5, i%5].imshow(cv2.cvtColor(pano, cv2.COLOR_BGR2RGB))\n",
    "    ax[i//5, i%5].set_title(pano_id)\n",
    "    ax[i//5, i%5].axis('off')\n",
    "    # Tight layout\n",
    "    fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count number of problems in semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subset of the dataset used in the qualitative evaluation (84 panoramas)\n",
    "pano_ids = {'0FHr9qesIVgabJ8hR7Uf2A', '1-TT8bGW5yAUXJKm40xrJQ', '1GIXHFehrd1Xbu2JbmzlFw', '1vSh2gNp3jJsrd1G_sl-BQ', '2atLrFYpUNAyUc7f7M8mzA', '3iQ5g0gAW8uyiTwiRNytaQ',\n",
    "            '2Yg6fuCTqr_5Uc5IcGPs4w', '0X1EzeV1Gae6VgvEonwc6w', '-juZj6rt9x1unIRBa0D7fQ', '2eQKbDNhkY-sD01QunNhjg', '2qShzHuplxE5Zp02V3Fnrw', '2uwdgegUMu_oMh5vILMtqg', \n",
    "            '1VO2N7ibSMEKWX0SAL4DoQ', '-RHS-ZYDt0sCDy2aS4AwOQ', '2fPjt5siCmoOpY1kMe3t3w', '_mx7T3kIbcEWe0NF28ohoQ', '-ELBA4Cjr_WBoetht0GVbQ', '2ZRURFi8Z58Od7a0tyK7oQ', \n",
    "            '0wLMkTJ7IaDz8mJm3uNeHg', '0sKrgbDBfDrizWjCnXI0FQ', '_Nkwp741bbV44txP6PRo1A', '2iKOp2S2_K4WrxfLS1jDlA', '0xS8FZwZ3ueZuMoD1Okywg', '1ex08CPMxpK3rK38W5gmRA', \n",
    "            '-ay7zopCWOrSjeUuirk91A', '-paSEQ-OawExso6Za-T-ug', '1VEVLWYfmi0vVyEsXoJD8A', '2E3r3TggV5YhVAYv1q0euA', '3BronM9R13wOkieBgnTV5w', '0yCv0ur6psBphmog_DOTOQ', \n",
    "            '4XfWRDhr6JF0kaotjzOKeQ', '0WuvMRCqZvf5e_unk3EG3Q', '3d2ja9krEsxrAcl1UYSH6g', '0KsmEkVuSWOERkQZ6ZgF-w', '5CIoi-u3-z4tCk5-5MXpxw', '3R9FNgg-dKle9aW5LsbnXQ', \n",
    "            '2EoZiLmHGl61m3r1wp4x8w', '1GYNc35brG1DJCtFYWs8KA', '0m9Or3xbo7JvO34d39YHSg', '4mw9TKPCSU7UbOpj55JGtw', '1KVPOen47WIgzsK0mMohNg', '1WQkqFs-U-85F5TzNZ6smQ', \n",
    "            '0E_M8eWvyACpG_fUq4TFrQ', '1sn9J4pmBrGqPClank2kiw', '-75fMXMEzhJHhe7FBqSRAw', '1sMhc-pYJPzUCZi40ZzDqg', '-WI1nKjShmeFVRGsrFsFpw', '_EHBpNS1aJR8rCWf_7a93A', \n",
    "            '0h2CfQQ_Ca5sRgU5Zze01g', '2ke_0eGW8-nEpc1cFyBM2A', '0jukKJk2AKvpFR7l88fHUA', '4w05JbqOnGLYHAt6zKDbZQ', '2uAdFMxVC3otCoJUJNaxmw', '3R5bt2FGbk3HWXKuUxno8w', \n",
    "            '_A3VGaMhL4XcGQxtFUiAfA', '4hVg_tOU2RRNlx_t1Zl6Lw', '3csQYBZY-qDW7hWrCf89zw', '_-7gKmiV-npQwLy_CD3v7Q', '0NjLmtmwNh95YlOyyydtnA', '2FdyeM1CVFiFKeDzQCHTkw', \n",
    "            '_WZ_Q2QCOe9NEypucJnClQ', '2ZM6bXf8ZZvdpsddMHIS1Q', '-NVzemAJVgKxPc5icSUDxw', '-rU6BN-wNeRclahZxn2nug', '_ZuTw7GC38rShAUjL-dLmQ', '2pgXiZXvZ8nqablHtAOL_A', \n",
    "            '2-VGJOr3z6Xq0PZjn-3HIg', '-qi4eywPKVd0sHlHqcWVkA', '0sAG8-ozIw7wANw_hsTCHA', '_C1U2haxCCmEyOsiC_PQ2w', '-omjTAq5SaYYZWZEPmFqbA', '-I6Ikjopy1WKUGc3RRueLA', \n",
    "            '-CD3qZk9zyeumBU_w7Yl5A', '_YIVijia4obgMONc9a-Vsg', '4Wy_JKfQ0yKteDeiHg2TxQ', '3FqdF-LCwp9hyf2V6V2YEg', '_pjTmksYX5Vpgoqm_GSOKA', '0vrKe1xEAZkxUXYhtwRtaQ', \n",
    "            '5aikoK5Fm_l-jopIV0n9LQ', '4wDHo4_KCawwsEv8tHX_Qw', '3T1QwrFPgOoYScEgEjJONg', '5f5MCY9UOi1m1W2ppnHNXw', '4n3TQoipOOfVc7HyGYooUQ', '4Z0NGEN7MFBphGkxa0Wpmw'}\n",
    "\n",
    "seg_path = '/var/scratch/lombardo/download_PS/segmented_B_0.25'\n",
    "output_dir = '/var/scratch/lombardo/download_PS/seg_analysis_B_0.25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_dir not in os.listdir('/var/scratch/lombardo/download_PS'):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# For each pano id in pano_ids, take the four 'grounded_sam_output_{face}.jpg', copy in output_dir, rename in '{pano_id}_grounded_sam_output_{face}.jpg', and then go to the next pano\n",
    "# face in ['front', 'back', 'left', 'right']\n",
    "for pano_id in pano_ids:\n",
    "    for face in ['front', 'back', 'left', 'right']:\n",
    "        src = os.path.join(seg_path, pano_id, f'grounded_sam_output_{face}.jpg')\n",
    "        dst = os.path.join(output_dir, f'{pano_id}_grounded_sam_output_{face}.jpg')\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artscraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d29a3d17092ddaa6405edc86ab0901537f3c31e71606c78d81c4b7eacb3d8b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
